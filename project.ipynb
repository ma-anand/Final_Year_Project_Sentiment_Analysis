{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ma-anand/Final_Year_Project_Sentiment_Analysis/blob/main/project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# installing kaggle library\n",
        "! pip install kaggle"
      ],
      "metadata": {
        "id": "r6ncUmHYjGYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Configuring the path of Kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "KboJIFo3jTfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Twitter Sentiment Dataset"
      ],
      "metadata": {
        "id": "B_YVQlJ7nDan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# API to fetch the dataset from kaggle\n",
        "!kaggle datasets download -d kazanova/sentiment140"
      ],
      "metadata": {
        "id": "AOHCdBEFm6wG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the compressed dataset\n",
        "\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/sentiment140.zip'\n",
        "\n",
        "with ZipFile(dataset, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print(\"Data set is extracted\")"
      ],
      "metadata": {
        "id": "dtvPUvnEndJO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Dependencies"
      ],
      "metadata": {
        "id": "mU-lIHAbojUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "metadata": {
        "id": "RpqpE3FBoogv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "id": "DdPPOOO3qKZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "akceNVDzqdHj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data processing"
      ],
      "metadata": {
        "id": "VLK1lpmTrUx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the data from csv file to pandas dataframe\n",
        "twitter_data= pd.read_csv('/content/training.1600000.processed.noemoticon.csv', encoding= 'ISO-8859-1')"
      ],
      "metadata": {
        "id": "VcUs_0HQrO3M"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91zrXbwkvTXH",
        "outputId": "2256abb4-6b31-436b-ccce-1ded6219bd90"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1599999, 6)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# naming the columns and reading the dataset\n",
        "column_names = ['Target','Id','Data','flag','User','Text']\n",
        "twitter_data= pd.read_csv('/content/training.1600000.processed.noemoticon.csv', names=column_names, encoding= 'ISO-8859-1')"
      ],
      "metadata": {
        "id": "q7awqyKTvau0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_data.head()"
      ],
      "metadata": {
        "id": "wAPfw5ntwjds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# counting the number of missing values in the dataset\n",
        "twitter_data.isnull().sum()"
      ],
      "metadata": {
        "id": "88q9zqdaxLo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the distribution of taget column\n",
        "twitter_data['Target'].value_counts()"
      ],
      "metadata": {
        "id": "1w0i-oRXxWp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LE2grgXOyRcu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}